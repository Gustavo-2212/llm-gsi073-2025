{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMXZbNQU2agZwF3MIs/vVM9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gustavo-2212/llm-gsi073-2025/blob/main/atv02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GnZogM5Wqcc2"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn import datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "X = X[y != 1]\n",
        "y = y[y != 1]\n",
        "y = torch.tensor(y, dtype=torch.float32)\n",
        "y[y == 0] = -1\n",
        "\n",
        "X = torch.tensor(X, dtype=torch.float32)"
      ],
      "metadata": {
        "id": "D3sHCPrZqlb3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_features = X.shape[1]\n",
        "w = torch.randn(n_features, 1, requires_grad=True)\n",
        "b = torch.zeros(1, requires_grad=True)\n",
        "\n",
        "learning_rate = 0.01\n",
        "epochs = 300\n",
        "optimizer = optim.Adam([w, b], lr=learning_rate)"
      ],
      "metadata": {
        "id": "vC1f2zzAq75A"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "    optimizer.zero_grad()\n",
        "    y_pred = X @ w + b\n",
        "    perda_de_classificacao = torch.clamp(1 - y.view(-1, 1) * y_pred, min=0).mean()\n",
        "    perda_de_distancia_entre_classes = 0.5 * torch.sum(w ** 2)\n",
        "\n",
        "    loss = perda_de_distancia_entre_classes + perda_de_classificacao\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if(epoch + 1) % 100 == 0:\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Loss={loss.item():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dj4G4M_hrNgU",
        "outputId": "4ad135f9-d396-4fae-e281-5487425cd077"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 100/300, Loss=0.1653\n",
            "Epoch 200/300, Loss=0.1426\n",
            "Epoch 300/300, Loss=0.1250\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    scores = X @ w + b\n",
        "    predictions = torch.where(scores > 0, torch.tensor(2.0), torch.tensor(-1.0))\n",
        "    correct = (predictions.view(-1) == y).float().sum()\n",
        "    accuracy = correct / y.shape[0]\n",
        "\n",
        "    print(f\"Acurácia: {accuracy.item() * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-9RYPCfsDNI",
        "outputId": "a89e429d-ebdd-4c35-f6a6-32fa8971a436"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparação: SVM x Regressão Logística\n",
        "\n",
        "> Embora ambos sejam classificadores lineares e frequentemente alcancem acurácias similares em problemas simples, eles funcionam de formas fundamentalmente diferetes:\n",
        "\n",
        "1. Regressão Logística\n",
        "* Objetivo probabilístico, tentando maximizar a verossimilhança dos dados;\n",
        "* Função de perda (Log Loss - BCEWithLogitsLoss), penalizando o erro de probabilidade suavemente;\n",
        "* Foco considerando todos ospontos;\n",
        "* Saída é um valor de probabilidade (0 a 1).\n",
        "\n",
        "2. SVM\n",
        "* Objetivo geométrico tentando maximizar a marge (a linha mais larga possível) entre as classes;\n",
        "* Função de perda Hinger Loss (1 - y*pred) zera o erro se o ponto estiver correto e fora da margem;\n",
        "* Foco apenas nos vetores de suporte (pontos difíceis perto da fronteira). Pontos fáceis são ignorados;\n",
        "* Distância para o hiperplano (score real) é retornado na saída.\n",
        "\n",
        "> Como as classes (Setosa e Virgínica) são linearmente separáveis com facilidade, ambos os modelos provavelmente chegarão a 100% de acurácia, mas a reta desenhada pelo SVM será a que está mais \"centralizada\" entre os dois grupos."
      ],
      "metadata": {
        "id": "iQ91_naUs0Mp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Usando nn.Linear\n"
      ],
      "metadata": {
        "id": "hVkM_bsvuISz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn import datasets\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "X = X[y != 1]\n",
        "y = y[y != 1]\n",
        "y = torch.tensor(y, dtype=torch.float32)\n",
        "y[y == 0] = -1\n",
        "\n",
        "X = torch.tensor(X, dtype=torch.float32)\n",
        "n_features = X.shape[1]\n",
        "\n",
        "modelo = nn.Linear(n_features, 1)\n",
        "\n",
        "learning_rate = 0.01\n",
        "epochs = 300\n",
        "optimizer = optim.Adam(modelo.parameters(), lr=learning_rate)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    y_pred = modelo(X)\n",
        "\n",
        "    perda_de_classificacao = torch.clamp(1 - y.view(-1, 1) * y_pred, min=0).mean()\n",
        "    perda_de_distancia_entre_classes = 0.5 * torch.sum(modelo.weight ** 2)\n",
        "\n",
        "    loss = perda_de_distancia_entre_classes + perda_de_classificacao\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if(epoch + 1) % 100 == 0:\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Loss={loss.item():.4f}\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    scores = modelo(X)\n",
        "    preds = torch.where(scores > 0, torch.tensor(2.0), torch.tensor(-1.0))\n",
        "    acc = (preds.view(-1) == y).float().mean()\n",
        "    print(f\"Acurácia Final: {acc.item():.2%}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t49YaPE3uJ7a",
        "outputId": "5198af0e-e512-413e-ca6b-4175cf6ac2c4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 100/300, Loss=0.1311\n",
            "Epoch 200/300, Loss=0.1077\n",
            "Epoch 300/300, Loss=0.0989\n",
            "Acurácia Final: 100.00%\n"
          ]
        }
      ]
    }
  ]
}