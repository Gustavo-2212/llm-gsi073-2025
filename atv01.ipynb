{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPfMTmYh9AndkBFm/UCGCBt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gustavo-2212/llm-gsi073-2025/blob/main/atv01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yt4EgQKUks7n"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import sklearn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iris = sklearn.datasets.load_iris()\n",
        "X = iris.data\n",
        "y = (iris.target == 1).astype(float)\n",
        "\n",
        "X = torch.tensor(X, dtype=torch.float32)\n",
        "y = torch.tensor(y, dtype=torch.float32).view(-1, 1)"
      ],
      "metadata": {
        "id": "q1Je4Fn7lCH9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelo = torch.nn.Linear(4, 1)\n",
        "funcao_perda = torch.nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.SGD(modelo.parameters(), lr=0.1)"
      ],
      "metadata": {
        "id": "LP-1A4L6lVQk"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1000):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = modelo(X)\n",
        "    loss = funcao_perda(outputs, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if(epoch + 1) % 10 == 0:\n",
        "        print(f\"Época [{epoch+1}/100], Loss: {loss.item():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3cgsc7Ylgyt",
        "outputId": "e459d477-5dd6-448c-af78-513ad2dc6174"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Época [10/100], Loss: 0.6376\n",
            "Época [20/100], Loss: 0.6154\n",
            "Época [30/100], Loss: 0.6050\n",
            "Época [40/100], Loss: 0.5991\n",
            "Época [50/100], Loss: 0.5951\n",
            "Época [60/100], Loss: 0.5920\n",
            "Época [70/100], Loss: 0.5894\n",
            "Época [80/100], Loss: 0.5871\n",
            "Época [90/100], Loss: 0.5849\n",
            "Época [100/100], Loss: 0.5828\n",
            "Época [110/100], Loss: 0.5808\n",
            "Época [120/100], Loss: 0.5789\n",
            "Época [130/100], Loss: 0.5771\n",
            "Época [140/100], Loss: 0.5753\n",
            "Época [150/100], Loss: 0.5736\n",
            "Época [160/100], Loss: 0.5719\n",
            "Época [170/100], Loss: 0.5703\n",
            "Época [180/100], Loss: 0.5688\n",
            "Época [190/100], Loss: 0.5673\n",
            "Época [200/100], Loss: 0.5658\n",
            "Época [210/100], Loss: 0.5644\n",
            "Época [220/100], Loss: 0.5630\n",
            "Época [230/100], Loss: 0.5617\n",
            "Época [240/100], Loss: 0.5604\n",
            "Época [250/100], Loss: 0.5592\n",
            "Época [260/100], Loss: 0.5580\n",
            "Época [270/100], Loss: 0.5568\n",
            "Época [280/100], Loss: 0.5557\n",
            "Época [290/100], Loss: 0.5546\n",
            "Época [300/100], Loss: 0.5535\n",
            "Época [310/100], Loss: 0.5525\n",
            "Época [320/100], Loss: 0.5514\n",
            "Época [330/100], Loss: 0.5505\n",
            "Época [340/100], Loss: 0.5495\n",
            "Época [350/100], Loss: 0.5486\n",
            "Época [360/100], Loss: 0.5477\n",
            "Época [370/100], Loss: 0.5469\n",
            "Época [380/100], Loss: 0.5460\n",
            "Época [390/100], Loss: 0.5452\n",
            "Época [400/100], Loss: 0.5444\n",
            "Época [410/100], Loss: 0.5436\n",
            "Época [420/100], Loss: 0.5429\n",
            "Época [430/100], Loss: 0.5421\n",
            "Época [440/100], Loss: 0.5414\n",
            "Época [450/100], Loss: 0.5407\n",
            "Época [460/100], Loss: 0.5401\n",
            "Época [470/100], Loss: 0.5394\n",
            "Época [480/100], Loss: 0.5388\n",
            "Época [490/100], Loss: 0.5382\n",
            "Época [500/100], Loss: 0.5375\n",
            "Época [510/100], Loss: 0.5370\n",
            "Época [520/100], Loss: 0.5364\n",
            "Época [530/100], Loss: 0.5358\n",
            "Época [540/100], Loss: 0.5353\n",
            "Época [550/100], Loss: 0.5347\n",
            "Época [560/100], Loss: 0.5342\n",
            "Época [570/100], Loss: 0.5337\n",
            "Época [580/100], Loss: 0.5332\n",
            "Época [590/100], Loss: 0.5327\n",
            "Época [600/100], Loss: 0.5323\n",
            "Época [610/100], Loss: 0.5318\n",
            "Época [620/100], Loss: 0.5314\n",
            "Época [630/100], Loss: 0.5309\n",
            "Época [640/100], Loss: 0.5305\n",
            "Época [650/100], Loss: 0.5301\n",
            "Época [660/100], Loss: 0.5297\n",
            "Época [670/100], Loss: 0.5293\n",
            "Época [680/100], Loss: 0.5289\n",
            "Época [690/100], Loss: 0.5285\n",
            "Época [700/100], Loss: 0.5281\n",
            "Época [710/100], Loss: 0.5278\n",
            "Época [720/100], Loss: 0.5274\n",
            "Época [730/100], Loss: 0.5271\n",
            "Época [740/100], Loss: 0.5267\n",
            "Época [750/100], Loss: 0.5264\n",
            "Época [760/100], Loss: 0.5261\n",
            "Época [770/100], Loss: 0.5257\n",
            "Época [780/100], Loss: 0.5254\n",
            "Época [790/100], Loss: 0.5251\n",
            "Época [800/100], Loss: 0.5248\n",
            "Época [810/100], Loss: 0.5245\n",
            "Época [820/100], Loss: 0.5242\n",
            "Época [830/100], Loss: 0.5239\n",
            "Época [840/100], Loss: 0.5237\n",
            "Época [850/100], Loss: 0.5234\n",
            "Época [860/100], Loss: 0.5231\n",
            "Época [870/100], Loss: 0.5228\n",
            "Época [880/100], Loss: 0.5226\n",
            "Época [890/100], Loss: 0.5223\n",
            "Época [900/100], Loss: 0.5221\n",
            "Época [910/100], Loss: 0.5218\n",
            "Época [920/100], Loss: 0.5216\n",
            "Época [930/100], Loss: 0.5214\n",
            "Época [940/100], Loss: 0.5211\n",
            "Época [950/100], Loss: 0.5209\n",
            "Época [960/100], Loss: 0.5207\n",
            "Época [970/100], Loss: 0.5205\n",
            "Época [980/100], Loss: 0.5202\n",
            "Época [990/100], Loss: 0.5200\n",
            "Época [1000/100], Loss: 0.5198\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelo.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    logits = modelo(X)\n",
        "    y_pred_prob = torch.sigmoid(logits)\n",
        "    y_pred_class = y_pred_prob.round()\n",
        "\n",
        "    acertos = (y_pred_class == y).sum().item()\n",
        "    total = y.size(0)\n",
        "    acuracia = acertos /total\n",
        "\n",
        "    print(f\"\"\"Total de amostras: {total}\n",
        "Total de acertos: {acertos}\n",
        "Acurácia do modelo: {acuracia * 100:.2f}%\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXfUWeInmuUE",
        "outputId": "6161b0f3-119b-4e01-956c-5d27188790c8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de amostras: 150\n",
            "Total de acertos: 104\n",
            "Acurácia do modelo: 69.33%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## O que tem em [nn.Linear]\n",
        "\n",
        "> É uma representação matemática de uma transformação linear. Armazenando os parâmetros aprendíveis que o otimizador(SGD) está tentando ajustar. Faz a relação entre as entradas X e as saídas y, levando em consideração os pesos e os viés.\n",
        "\n"
      ],
      "metadata": {
        "id": "Rhpi4LHUnROd"
      }
    }
  ]
}